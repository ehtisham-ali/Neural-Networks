# Backpropagation

Problem-1 "Logistic Regression"
In this exercise, I implemented a multinomial logistic regression model with tensorflow for Fashion-MNIST dataset. Cross Validation was used to find the best regularization parameter  ùúÜ  for the L2-regularization term. Fashion-MNIST dataset is similar to the sklearn Digit dataset you used in the Project 1. It contains 60,000 training images and 10,000 testing images. Each example is a 28√ó28 grayscale image, associated with a label from 10 classes.

Multinomial logistic regression is a probabilistic, linear classifier. It is parametrized by a weight matrix  ùëä  and a bias vector  ùëè . Classification is done by projecting an input vector onto a set of hyperplanes, each of which corresponds to a class. The distance from the input to a hyperplane reflects the probability that the input is a member of the corresponding class.


Problem-2  "BackPropagation"
In the following exercise I build a feed-forward network from scratch using only Numpy. For this, I implemented Back-propagation in python. Additionally, this network had the option of L2 regularization enabled within it.

 

## File Description

The project contains the following files:

  - `backpropagation.py`: 




